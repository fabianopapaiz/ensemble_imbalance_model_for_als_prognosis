{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "#needed to import utils.py\n",
    "sys.path.append('../') \n",
    "\n",
    "import utils\n",
    "import utils_preprocessing\n",
    "import utils_exec_models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# $Ensemble$-$Imbalance$ scenario\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the scaled Training and Validation subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Site_Onset</th>\n",
       "      <th>Diagnosis_Delay</th>\n",
       "      <th>Age_at_Onset</th>\n",
       "      <th>Riluzole</th>\n",
       "      <th>FVC_at_Diagnosis</th>\n",
       "      <th>BMI_at_Diagnosis</th>\n",
       "      <th>Q1_Speech_slope_at_Diagnosis</th>\n",
       "      <th>Q2_Salivation_slope_at_Diagnosis</th>\n",
       "      <th>Q3_Swallowing_slope_at_Diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>Q7_Turning_in_Bed_slope_at_Diagnosis</th>\n",
       "      <th>Q8_Walking_slope_at_Diagnosis</th>\n",
       "      <th>Q9_Climbing_Stairs_slope_at_Diagnosis</th>\n",
       "      <th>Q10_Respiratory_slope_at_Diagnosis</th>\n",
       "      <th>Qty_Regions_Involved_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Bulbar_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Upper_Limb_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Lower_Limb_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Respiratory_at_Diagnosis</th>\n",
       "      <th>Patient_with_Gastrostomy_at_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_Male  Site_Onset  Diagnosis_Delay  Age_at_Onset  Riluzole  \\\n",
       "0       1.0         1.0              0.0          0.50       0.0   \n",
       "1       1.0         1.0              0.5          0.75       0.0   \n",
       "2       1.0         1.0              0.0          0.25       0.0   \n",
       "3       0.0         0.0              0.5          0.50       0.0   \n",
       "4       1.0         0.0              1.0          0.75       0.0   \n",
       "\n",
       "   FVC_at_Diagnosis  BMI_at_Diagnosis  Q1_Speech_slope_at_Diagnosis  \\\n",
       "0               1.0              0.67                           0.0   \n",
       "1               0.0              0.67                           0.0   \n",
       "2               1.0              0.33                           0.5   \n",
       "3               1.0              1.00                           0.5   \n",
       "4               0.0              1.00                           0.0   \n",
       "\n",
       "   Q2_Salivation_slope_at_Diagnosis  Q3_Swallowing_slope_at_Diagnosis  ...  \\\n",
       "0                               0.0                               0.0  ...   \n",
       "1                               0.0                               0.0  ...   \n",
       "2                               0.0                               0.0  ...   \n",
       "3                               0.5                               0.5  ...   \n",
       "4                               0.0                               0.0  ...   \n",
       "\n",
       "   Q7_Turning_in_Bed_slope_at_Diagnosis  Q8_Walking_slope_at_Diagnosis  \\\n",
       "0                                   0.0                            0.0   \n",
       "1                                   0.0                            0.0   \n",
       "2                                   0.0                            0.0   \n",
       "3                                   0.5                            0.5   \n",
       "4                                   0.0                            0.0   \n",
       "\n",
       "   Q9_Climbing_Stairs_slope_at_Diagnosis  Q10_Respiratory_slope_at_Diagnosis  \\\n",
       "0                                    0.0                                 0.0   \n",
       "1                                    0.5                                 0.0   \n",
       "2                                    0.5                                 0.0   \n",
       "3                                    0.5                                 0.5   \n",
       "4                                    0.5                                 0.0   \n",
       "\n",
       "   Qty_Regions_Involved_at_Diagnosis  Region_Involved_Bulbar_at_Diagnosis  \\\n",
       "0                               0.67                                  1.0   \n",
       "1                               0.67                                  1.0   \n",
       "2                               0.67                                  1.0   \n",
       "3                               0.67                                  1.0   \n",
       "4                               1.00                                  1.0   \n",
       "\n",
       "   Region_Involved_Upper_Limb_at_Diagnosis  \\\n",
       "0                                      1.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   Region_Involved_Lower_Limb_at_Diagnosis  \\\n",
       "0                                      1.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      1.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   Region_Involved_Respiratory_at_Diagnosis  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       1.0   \n",
       "4                                       1.0   \n",
       "\n",
       "   Patient_with_Gastrostomy_at_Diagnosis  \n",
       "0                                    0.0  \n",
       "1                                    0.0  \n",
       "2                                    0.0  \n",
       "3                                    0.0  \n",
       "4                                    0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = utils.get_train_and_validation_data(scaled=True)\n",
    "\n",
    "X_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Read the Single-Model results file and get all unique $Model+Hyperparameters$\n",
    "### NOTE: DO NOT re-execute all models, see `classif_filtered` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=10, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=15, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=25, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=10, random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=15, random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=25, random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=50, random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=200,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=50,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=75,\n",
      "                       random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=10, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=10, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=10, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=15, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=15, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=15, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=15, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=25, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=25, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=25, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=25, n_estimators=75, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=50, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=50, n_estimators=200, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=50, n_estimators=50, random_state=42)',\n",
      "    'RandomForestClassifier(max_depth=50, n_estimators=75, random_state=42)',\n",
      "]\n",
      "CPU times: user 167 ms, sys: 1 Âµs, total: 167 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get a Set of models from the results CSV without repeating\n",
    "dir_dest = os.path.abspath('exec_results/')\n",
    "\n",
    "results_csv_file = f'{dir_dest}/results_Single_Model.csv'\n",
    "\n",
    "classifiers = utils_exec_models.get_models_set_from_results(results_csv_file=results_csv_file)\n",
    "# display(classifiers)\n",
    "\n",
    "\n",
    "model_classes = [\n",
    "# OK    'SVC',\n",
    "    #\n",
    "# OK    'GaussianNB', \n",
    "# OK    'ComplementNB', \n",
    "    #\n",
    "# OK    'MLPClassifier', \n",
    "    #\n",
    "# OK    'DecisionTreeClassifier', \n",
    "    #\n",
    "# OK    'RadiusNeighborsClassifier', \n",
    "# OK    'KNeighborsClassifier',\n",
    "    #\n",
    "    'RandomForestClassifier', \n",
    "]\n",
    "\n",
    "\n",
    "classif_filtered = []\n",
    "for clf in classifiers:\n",
    "    clf_model_class = str(clf).split('(')[0]\n",
    "    to_exec = (clf_model_class in model_classes)\n",
    "    if to_exec:\n",
    "        classif_filtered.append(clf)\n",
    "\n",
    "    \n",
    "classifiers = classif_filtered.copy()        \n",
    "        \n",
    "\n",
    "utils.print_array_as_list(classifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Models using GridSearch using the inputs and outputs created in the previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the `param_grid`Â´s that will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 96 param_grids will be executed\n",
      "\n",
      "CPU times: user 2.84 ms, sys: 0 ns, total: 2.84 ms\n",
      "Wall time: 2.84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## define the models and hyperparameters for the GridSearch\n",
    "param_grids = []\n",
    "\n",
    "TESTING = True\n",
    "TESTING = False\n",
    "\n",
    "if len(classifiers) > 0:\n",
    "\n",
    "    # execute GridSearch for each classifiers \n",
    "    for classifier in classifiers:\n",
    "        \n",
    "        param_grid = []\n",
    "        \n",
    "        _ = utils_exec_models.create_models_BalancedBagging_grid(\n",
    "            classifiers=[classifier],\n",
    "            param_grid=param_grid, \n",
    "            testing=TESTING,\n",
    "        )\n",
    "\n",
    "        # store the param_grid's that will be executed\n",
    "        param_grids.append(param_grid)\n",
    "        \n",
    "        if TESTING and len(param_grids) >= 5:\n",
    "            break\n",
    "        \n",
    "\n",
    "# utils.print_array_as_list(param_grids)        \n",
    "        \n",
    "print(f'A total of {len(param_grids)} param_grids will be executed')\n",
    "print()\n",
    "\n",
    "# utils.print_array_as_list(param_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models added to  `param_grid`Â´s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/96) Executing RandomForestClassifier... Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_results_saved = os.path.abspath('exec_results/results_Ensemble_Imbalance.csv')\n",
    "\n",
    "\n",
    "# verify if already exists an CSV with the results\n",
    "overwrite_results_saved_previously = False\n",
    "\n",
    "if os.path.exists(csv_results_saved) and overwrite_results_saved_previously==False:\n",
    "    print('Reading results saved previously...')\n",
    "    df_results = utils.read_csv(csv_file=csv_results_saved)\n",
    "else:\n",
    "    df_results = None\n",
    "\n",
    "\n",
    "kfold = utils_exec_models.get_kfold_splits()\n",
    "\n",
    "was_executed = False\n",
    "\n",
    "if len(param_grids) > 0:\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    tot = len(param_grids)\n",
    "    \n",
    "    # execute GridSearch for each classifiers \n",
    "    for p_grid in param_grids:\n",
    "        \n",
    "        if i > 0 and not was_executed:\n",
    "#             pass\n",
    "            time.sleep((1 if TESTING else 5))\n",
    "            clear_output()\n",
    "\n",
    "        was_executed = False\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "        estimator_class = p_grid[0]['classifier__estimator'][0]\n",
    "        \n",
    "        estimator_name = str(estimator_class).split('(')[0]\n",
    "\n",
    "        estimator_desc = utils.get_model_description(estimator_name)\n",
    "        \n",
    "        estimator_params = estimator_class.get_params()    \n",
    "        estimator_params = utils_exec_models.convert_hyperparams_to_dict(estimator_params)\n",
    "\n",
    "        # check if model was already executed\n",
    "        if df_results is not None:\n",
    "            df_executed = df_results.loc[\n",
    "                (df_results.Estimator_Desc == str(estimator_desc))\n",
    "               &(df_results.Estimator_Class == str(estimator_name)) \n",
    "               &(df_results.Estimator_Hyperparams == str(estimator_params)) \n",
    "            ].copy()\n",
    "            \n",
    "            if df_executed.shape[0] > 0:\n",
    "                print(f'{i:>3} was already executed')\n",
    "                was_executed = True\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        print(f'({i}/{tot}) Executing {estimator_name}...', end=' ')\n",
    "        \n",
    "        ## execute GridSearch\n",
    "        grid, df_results_aux = utils_exec_models.exec_grid_search(\n",
    "            param_grid=p_grid, \n",
    "            X=X_train, \n",
    "            y=y_train,\n",
    "            cv=kfold,\n",
    "            verbose=1,\n",
    "            return_train_score=False,\n",
    "            sort_results=False,\n",
    "            dataset_info='Ensemble-Imbalance',\n",
    "            features_info='All Features',\n",
    "            n_jobs=6, \n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        df_results_aux['Estimator_Desc'] = str(estimator_desc)\n",
    "        df_results_aux['Estimator_Class'] = str(estimator_name)\n",
    "        df_results_aux['Estimator_Hyperparams'] = str(estimator_params)\n",
    "        \n",
    "\n",
    "        if df_results is None:\n",
    "            df_results = df_results_aux\n",
    "        else:\n",
    "            df_results = pd.concat([df_results, df_results_aux])\n",
    "\n",
    "        # delete results witn NAN in the Balanced Accuracy\n",
    "        to_delete = df_results.loc[(df_results.BalAcc.isnull())]\n",
    "        df_results = utils.remove_rows(df=df_results, to_delete=to_delete)\n",
    "    \n",
    "        print('saving and waiting...')\n",
    "\n",
    "        # sort performances results and show results\n",
    "        df_results = utils_exec_models.sort_performances_results(df=df_results)       \n",
    "\n",
    "        # save the results\n",
    "        utils.save_to_csv(df=df_results, csv_file=csv_results_saved)\n",
    "\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "#         break\n",
    "\n",
    "display(df_results.head(10))\n",
    "       \n",
    "\n",
    "print()\n",
    "print('FINISHED !!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neural Networks', 'SVM', 'NaÃ¯ve Bayes', 'k-NN'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.Estimator_Desc.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test create a classifier using the  model + hyperparams from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42,\n",
      "                                                  solver='sgd'),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='all')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42,\n",
      "                                                  solver='sgd'),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='majority')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42,\n",
      "                                                  solver='sgd'),\n",
      "                          n_estimators=3, random_state=42)\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42,\n",
      "                                                  solver='sgd'),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='all')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42,\n",
      "                                                  solver='sgd'),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='majority')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42,\n",
      "                                                  solver='sgd'),\n",
      "                          n_estimators=3, random_state=42)\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='all')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='all')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='majority')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42)\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='majority')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23),\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42)\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23,\n",
      "                                                                      23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='majority')\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23,\n",
      "                                                                      23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42)\n",
      "\n",
      "BalancedBaggingClassifier(estimator=MLPClassifier(hidden_layer_sizes=(23, 23,\n",
      "                                                                      23),\n",
      "                                                  learning_rate='adaptive',\n",
      "                                                  learning_rate_init=0.7,\n",
      "                                                  max_iter=1000,\n",
      "                                                  random_state=42),\n",
      "                          n_estimators=3, random_state=42,\n",
      "                          sampling_strategy='all')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "dd = list()\n",
    "\n",
    "for index, row in df_results.iterrows():\n",
    "    dd.append([row.Classifier, row.Hyperparams, row.Estimator_Class, row.Estimator_Hyperparams])\n",
    "\n",
    "\n",
    "for m, h, est, est_h in dd:\n",
    "    \n",
    "    model = utils_exec_models.create_model_from_string(\n",
    "        model=m,\n",
    "        hyperparams=h,\n",
    "        estimator_model=est,\n",
    "        estimator_hyperparams=est_h\n",
    "    )\n",
    "\n",
    "#     model.fit(\n",
    "#         X_train, \n",
    "#         y_train[utils.CLASS_COLUMN].ravel()\n",
    "#     )\n",
    "    \n",
    "#     y_pred = model.predict(X_valid)\n",
    "    \n",
    "    print(model)\n",
    "#     print(y_pred)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show other grid properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'Best Bal.Acc.: {grid.best_score_:.2f}')\n",
    "print(f'        Model: {grid.best_params_[\"classifier\"]} ') \n",
    "print(f'Performance using the Validation set:  {grid.score(X_valid, y_valid):.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
