{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "#needed to import utils.py\n",
    "sys.path.append('../') \n",
    "\n",
    "import utils\n",
    "import utils_preprocessing\n",
    "import utils_exec_models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the scaled Training and Validation subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Site_Onset</th>\n",
       "      <th>Diagnosis_Delay</th>\n",
       "      <th>Age_at_Onset</th>\n",
       "      <th>Riluzole</th>\n",
       "      <th>FVC_at_Diagnosis</th>\n",
       "      <th>BMI_at_Diagnosis</th>\n",
       "      <th>Q1_Speech_slope_at_Diagnosis</th>\n",
       "      <th>Q2_Salivation_slope_at_Diagnosis</th>\n",
       "      <th>Q3_Swallowing_slope_at_Diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>Q7_Turning_in_Bed_slope_at_Diagnosis</th>\n",
       "      <th>Q8_Walking_slope_at_Diagnosis</th>\n",
       "      <th>Q9_Climbing_Stairs_slope_at_Diagnosis</th>\n",
       "      <th>Q10_Respiratory_slope_at_Diagnosis</th>\n",
       "      <th>Qty_Regions_Involved_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Bulbar_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Upper_Limb_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Lower_Limb_at_Diagnosis</th>\n",
       "      <th>Region_Involved_Respiratory_at_Diagnosis</th>\n",
       "      <th>Patient_with_Gastrostomy_at_Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_Male  Site_Onset  Diagnosis_Delay  Age_at_Onset  Riluzole  \\\n",
       "0       1.0         1.0              0.0          0.50       0.0   \n",
       "1       1.0         1.0              0.5          0.75       0.0   \n",
       "2       1.0         1.0              0.0          0.25       0.0   \n",
       "3       0.0         0.0              0.5          0.50       0.0   \n",
       "4       1.0         0.0              1.0          0.75       0.0   \n",
       "\n",
       "   FVC_at_Diagnosis  BMI_at_Diagnosis  Q1_Speech_slope_at_Diagnosis  \\\n",
       "0               1.0              0.67                           0.0   \n",
       "1               0.0              0.67                           0.0   \n",
       "2               1.0              0.33                           0.5   \n",
       "3               1.0              1.00                           0.5   \n",
       "4               0.0              1.00                           0.0   \n",
       "\n",
       "   Q2_Salivation_slope_at_Diagnosis  Q3_Swallowing_slope_at_Diagnosis  ...  \\\n",
       "0                               0.0                               0.0  ...   \n",
       "1                               0.0                               0.0  ...   \n",
       "2                               0.0                               0.0  ...   \n",
       "3                               0.5                               0.5  ...   \n",
       "4                               0.0                               0.0  ...   \n",
       "\n",
       "   Q7_Turning_in_Bed_slope_at_Diagnosis  Q8_Walking_slope_at_Diagnosis  \\\n",
       "0                                   0.0                            0.0   \n",
       "1                                   0.0                            0.0   \n",
       "2                                   0.0                            0.0   \n",
       "3                                   0.5                            0.5   \n",
       "4                                   0.0                            0.0   \n",
       "\n",
       "   Q9_Climbing_Stairs_slope_at_Diagnosis  Q10_Respiratory_slope_at_Diagnosis  \\\n",
       "0                                    0.0                                 0.0   \n",
       "1                                    0.5                                 0.0   \n",
       "2                                    0.5                                 0.0   \n",
       "3                                    0.5                                 0.5   \n",
       "4                                    0.5                                 0.0   \n",
       "\n",
       "   Qty_Regions_Involved_at_Diagnosis  Region_Involved_Bulbar_at_Diagnosis  \\\n",
       "0                               0.67                                  1.0   \n",
       "1                               0.67                                  1.0   \n",
       "2                               0.67                                  1.0   \n",
       "3                               0.67                                  1.0   \n",
       "4                               1.00                                  1.0   \n",
       "\n",
       "   Region_Involved_Upper_Limb_at_Diagnosis  \\\n",
       "0                                      1.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   Region_Involved_Lower_Limb_at_Diagnosis  \\\n",
       "0                                      1.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      1.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   Region_Involved_Respiratory_at_Diagnosis  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       1.0   \n",
       "4                                       1.0   \n",
       "\n",
       "   Patient_with_Gastrostomy_at_Diagnosis  \n",
       "0                                    0.0  \n",
       "1                                    0.0  \n",
       "2                                    0.0  \n",
       "3                                    0.0  \n",
       "4                                    0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = utils.get_train_and_validation_data(scaled=True)\n",
    "\n",
    "X_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Models using GridSearch using the inputs and outputs created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 719 candidates, totalling 3595 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/python-projects/_my_thesis/als_prognosis_using_ensemble_imbalance/05_Train_Validate_Models/../utils_exec_models.py\u001b[0m in \u001b[0;36mexec_grid_search\u001b[0;34m(param_grid, X, y, cv, n_jobs, verbose, scoring, refit, return_train_score, sort_results, dataset_info, features_info)\u001b[0m\n\u001b[1;32m    177\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     df_results = get_grid_search_performances(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_results_saved = os.path.abspath('exec_results/results_Single_Model.csv')\n",
    "\n",
    "\n",
    "i = 1\n",
    "\n",
    "\n",
    "# verify if already exists an CSV with the results\n",
    "overwrite_results_saved_previously = True\n",
    "\n",
    "if os.path.exists(csv_results_saved) and overwrite_results_saved_previously==False:\n",
    "    print('Reading results saved previously...')\n",
    "    df_results = utils.read_csv(csv_file=csv_results_saved)\n",
    "else:\n",
    "    df_results = None\n",
    "\n",
    "\n",
    "kfold = utils_exec_models.get_kfold_splits()\n",
    "\n",
    "\n",
    "## define the models and hyperparameters for the GridSearch\n",
    "param_grid = []\n",
    "\n",
    "TESTING = True\n",
    "TESTING = False\n",
    "\n",
    "utils_exec_models.create_models_SVM_grid(param_grid, testing=TESTING)\n",
    "utils_exec_models.create_models_NB_grid(param_grid, testing=TESTING)\n",
    "utils_exec_models.create_models_DT_grid(param_grid, testing=TESTING)\n",
    "utils_exec_models.create_models_kNN_grid(param_grid, testing=TESTING)\n",
    "utils_exec_models.create_models_RF_grid(param_grid, testing=TESTING)\n",
    "utils_exec_models.create_models_NN_grid(qty_features=X_train.shape[1],  param_grid=param_grid, testing=TESTING)\n",
    "\n",
    "#display(param_grid)\n",
    "\n",
    "\n",
    "if len(param_grid) > 0:\n",
    "\n",
    "    ## execute GridSearch\n",
    "    grid, df_results_aux = utils_exec_models.exec_grid_search(\n",
    "        param_grid=param_grid, \n",
    "        X=X_train, \n",
    "        y=y_train,\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        return_train_score=False,\n",
    "        sort_results=False,\n",
    "        dataset_info='Single-Model',\n",
    "        features_info='All Features',\n",
    "        #\n",
    "        n_jobs=8, \n",
    "    )\n",
    "\n",
    "    \n",
    "    if df_results is None:\n",
    "        df_results = df_results_aux\n",
    "    else:\n",
    "        df_results = pd.concat([df_results, df_results_aux])\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    \n",
    "print()\n",
    "print('FINISHED !!!')\n",
    "\n",
    "\n",
    "# sort performances results and show results\n",
    "df_results = utils_exec_models.sort_performances_results(df=df_results)       \n",
    "display(df_results)\n",
    "\n",
    "# save the results\n",
    "utils.save_to_csv(df=df_results, csv_file=csv_results_saved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# OTHERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test create a classifier using the  model + hyperparams from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.5, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.5, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.7, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.7, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=1, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.3, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.3, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1500, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=1500, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.1, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.1, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=100, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=100, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=200, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=200, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1000, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=1000, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.1, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.5, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.7, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=1, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=3, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=3, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=5, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=5, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=10, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=10, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1700, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=1700, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=2000, class_weight='balanced', kernel='linear', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=2000, class_weight='balanced', gamma='auto', kernel='linear',\n",
      "    probability=True, random_state=42)\n",
      "\n",
      "SVC(C=3, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.3, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.3, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.5, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "ComplementNB(alpha=0.5)\n",
      "\n",
      "ComplementNB()\n",
      "\n",
      "ComplementNB(alpha=1.5)\n",
      "\n",
      "ComplementNB(alpha=2.0)\n",
      "\n",
      "ComplementNB(alpha=2.5)\n",
      "\n",
      "ComplementNB(alpha=3.0)\n",
      "\n",
      "ComplementNB(alpha=3.5)\n",
      "\n",
      "ComplementNB(alpha=4.0)\n",
      "\n",
      "SVC(C=0.1, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=0.7, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=5, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=10, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "ComplementNB(alpha=0.1)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=4, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=3, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=7, random_state=42)\n",
      "\n",
      "GaussianNB()\n",
      "\n",
      "SVC(C=3, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=100, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=5, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=4, random_state=42)\n",
      "\n",
      "SVC(C=5, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=3, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=7, random_state=42)\n",
      "\n",
      "SVC(C=200, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=10, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=9, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=9, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=10, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "SVC(C=1000, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=10, probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=200, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "SVC(C=5, probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "SVC(C=100, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=100, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=200, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=200, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=2000, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=2000, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=100, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=3, probability=True, random_state=42)\n",
      "\n",
      "SVC(C=10, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=10, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "SVC(C=200, probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1000, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1700, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=1500, probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1700, probability=True, random_state=42)\n",
      "\n",
      "SVC(C=2000, probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=1000, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=1000, probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       n_estimators=50, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23,), learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=5, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=5, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1000, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1000, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1500, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1500, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1700, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1700, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=3, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=3, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=5, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "SVC(C=2000, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=1500, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=2000, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=1700, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "SVC(C=100, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=200, class_weight='balanced', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=100, probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=1500, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=10, n_estimators=200, random_state=42)\n",
      "\n",
      "SVC(C=10, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "SVC(C=0.5, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.5, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.7, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.7, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       n_estimators=200, random_state=42)\n",
      "\n",
      "SVC(C=1, probability=True, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "SVC(C=1500, class_weight='balanced', gamma='auto', probability=True,\n",
      "    random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=25, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=50, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=15, random_state=42)\n",
      "\n",
      "SVC(C=1700, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=2000, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23,), learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
      "                       random_state=42)\n",
      "\n",
      "SVC(C=0.3, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.3, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "SVC(C=3, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=25, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=50, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=9, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "RandomForestClassifier(max_depth=15, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "RandomForestClassifier(max_depth=10, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=10, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=15, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=15, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=25, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=25, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=50, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=50, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=15, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "DecisionTreeClassifier(max_depth=15, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=15, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=15, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=25, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=25, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=10, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=15, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=25, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=200, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=10, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=75, random_state=42)\n",
      "\n",
      "SVC(C=0.1, kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.1, gamma='auto', kernel='linear', probability=True, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "DecisionTreeClassifier(max_depth=25, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=50, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=10, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=9, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=7, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=25, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(max_depth=50, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(criterion='entropy', max_depth=50, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=4, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=200, random_state=42)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=5, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, random_state=42)\n",
      "\n",
      "SVC(C=0.7, probability=True, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=15, n_estimators=50, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=75, random_state=42)\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=3)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=75,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=15, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=15, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=25, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=25, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=50,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=200,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=25, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=50, n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=25,\n",
      "                       n_estimators=200, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       n_estimators=50, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       n_estimators=75, random_state=42)\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       n_estimators=200, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "SVC(C=0.5, probability=True, random_state=42)\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
      "                       n_estimators=200, random_state=42)\n",
      "\n",
      "SVC(C=1, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=3, weights='distance')\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', weights='distance')\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
      "                       random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=3, weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean')\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', weights='distance')\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=3)\n",
      "\n",
      "ComplementNB(alpha=0.1, norm=True)\n",
      "\n",
      "ComplementNB(alpha=0.5, norm=True)\n",
      "\n",
      "DecisionTreeClassifier(max_depth=3, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=9, weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "ComplementNB(norm=True)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=9)\n",
      "\n",
      "ComplementNB(alpha=1.5, norm=True)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "ComplementNB(alpha=2.0, norm=True)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "ComplementNB(alpha=3.0, norm=True)\n",
      "\n",
      "ComplementNB(alpha=2.5, norm=True)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "ComplementNB(alpha=3.5, norm=True)\n",
      "\n",
      "ComplementNB(alpha=4.0, norm=True)\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=15, weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "SVC(C=0.3, probability=True, random_state=42)\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=9, weights='distance')\n",
      "\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=15)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.7)\n",
      "\n",
      "SVC(C=0.7, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=9)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=15, weights='distance')\n",
      "\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=15)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', n_neighbors=3)\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', n_neighbors=3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "SVC(C=0.5, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', n_neighbors=9, weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', n_neighbors=9)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.5)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.5, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.7)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.7, weights='distance')\n",
      "\n",
      "SVC(C=0.1, probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.1, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "SVC(C=0.3, gamma='auto', probability=True, random_state=42)\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', n_neighbors=15)\n",
      "\n",
      "KNeighborsClassifier(metric='chebyshev', n_neighbors=15, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=50, metric='chebyshev', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=100, metric='chebyshev', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='euclidean', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='manhattan', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.3)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          radius=0.3, weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=0,\n",
      "                          weights='distance')\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1)\n",
      "\n",
      "RadiusNeighborsClassifier(leaf_size=200, metric='chebyshev', outlier_label=1,\n",
      "                          weights='distance')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23,),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23,),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42, solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=1e-05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.05,\n",
      "              hidden_layer_sizes=(23, 46, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42,\n",
      "              solver='sgd')\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 46, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(23, 46, 46, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23,), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.05, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.3, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 23, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46), learning_rate_init=0.7,\n",
      "              max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46), learning_rate='adaptive',\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate_init=0.7, max_iter=1000, random_state=42)\n",
      "\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=(23, 46, 46, 23),\n",
      "              learning_rate='adaptive', learning_rate_init=0.7, max_iter=1000,\n",
      "              random_state=42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "df_results = utils.read_csv(csv_file=csv_results_saved)\n",
    "\n",
    "dd = list()\n",
    "\n",
    "for index, row in df_results.iterrows():\n",
    "    dd.append([row.Classifier, row.Hyperparams])\n",
    "\n",
    "\n",
    "for m, h in dd:\n",
    "\n",
    "    model = utils_exec_models.create_model_from_string(\n",
    "        model=m,\n",
    "        hyperparams=h,\n",
    "    )\n",
    "\n",
    "#     model.fit(\n",
    "#         X_train, \n",
    "#         y_train[utils.CLASS_COLUMN].ravel()\n",
    "#     )\n",
    "    \n",
    "#     y_pred = model.predict(X_valid)\n",
    "    \n",
    "    print(model)\n",
    "#     print(y_pred)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show other grid properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'Best Bal.Acc.: {grid.best_score_:.2f}')\n",
    "print(f'        Model: {grid.best_params_[\"classifier\"]} ') \n",
    "print(f'Performance using the Validation set:  {grid.score(X_valid, y_valid):.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
